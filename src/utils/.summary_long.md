# Directory: src/utils/

## Overview
The utils directory provides essential utility functions that support the core functionality of the genai-lite library. It contains utilities for prompt processing including token counting, intelligent text preview generation, and a sophisticated template rendering engine. These utilities are crucial for managing LLM interactions, helping developers understand token usage for cost estimation and rate limiting, providing smart content truncation for better user experiences, and enabling dynamic prompt generation through template rendering.

## Key Components
### index.ts
## Overview
This file serves as the central export point for utility functions in the genai-lite library. It re-exports utilities from the prompt module and template engine module, providing functions for token counting, intelligent text preview generation, and template rendering to help manage LLM interactions and dynamic content generation.

## Key Components
- **Re-exports**: 
  - All functions from `./prompt` module
  - All functions from `./templateEngine` module
- **Exported functions**:
  - `countTokens(text: string, model?: TiktokenModel): number` - Counts tokens in text using model-specific tokenizers
  - `getSmartPreview(content: string, config: { minLines: number; maxLines: number }): string` - Generates intelligent content previews
  - `renderTemplate(template: string, variables: Record<string, any>): string` - Renders templates with variable substitution and conditional logic

## Architecture & Design
The file follows a barrel export pattern, providing a clean API surface for the utils module. The underlying prompt utilities implement:
- **Tokenizer caching**: Uses a Map to cache tokenizers for performance
- **Graceful fallback**: Falls back to character-based estimation (length/4) if tokenization fails
- **Smart truncation**: Preview generation looks for natural break points (empty lines) within configured bounds

## Dependencies
- **Internal**: `./prompt` module
- **External**: `js-tiktoken` library (used by prompt module for token counting)

## Integration Points
This utility module is likely used throughout the genai-lite library wherever:
- Token counting is needed for API request preparation
- Content needs to be previewed or truncated for display
- Prompt size management is required

## Usage Examples
```typescript
import { countTokens, getSmartPreview } from 'genai-lite/utils';

// Count tokens for GPT-4
const tokenCount = countTokens('Hello, world!', 'gpt-4');

// Generate a smart preview of long content
const preview = getSmartPreview(longText, { 
  minLines: 10, 
  maxLines: 50 
});
```

## See Also
- `src/utils/prompt.ts` - The actual implementation of prompt utilities
- LLM service modules that likely use these utilities for request preparation
- Any UI components that might use getSmartPreview for content display

### prompt.ts
## Overview
This module provides prompt-related utilities focused on token counting and intelligent text preview generation. It implements a cached tokenizer system for efficient token counting across different GPT models and offers a smart preview function that truncates content based on line count and natural break points.

## Key Components
- **tokenizerCache**: Map-based cache storing Tiktoken instances for different models to avoid re-initialization
- **getTokenizer(model)**: Internal function that retrieves or creates cached tokenizer instances for specific models
- **countTokens(text, model)**: Public function that counts tokens in text using the specified model's tokenizer (defaults to 'gpt-4')
- **getSmartPreview(content, config)**: Public function that creates intelligent previews of long content by finding natural break points

## Architecture & Design
The module implements a caching pattern for tokenizer instances to improve performance when counting tokens multiple times. The token counting function includes graceful fallback behavior (estimating 4 characters per token) when tokenization fails. The smart preview algorithm attempts to find natural content boundaries (empty lines) rather than cutting at arbitrary points.

## Dependencies
- **Internal**: None
- **External**: 
  - `js-tiktoken` - OpenAI's tiktoken library for accurate token counting

## Integration Points
This module is designed to be used by other parts of the system that need to:
- Calculate token usage for API rate limiting or cost estimation
- Generate previews of file contents for display in UI or prompts
- Prepare content for LLM consumption with token awareness

## Usage Examples
```typescript
// Count tokens in text
const tokenCount = countTokens("Hello world", "gpt-4");

// Generate a smart preview of long content
const preview = getSmartPreview(longFileContent, {
  minLines: 50,
  maxLines: 100
});
```

## See Also
- Components that build prompts for LLM requests
- Services that need to estimate API costs based on token counts
- UI components displaying file previews

### prompt.test.ts
## Overview
This test file provides comprehensive coverage for the prompt utilities module, which includes token counting functionality using js-tiktoken and smart text preview generation. The tests ensure that token counting works accurately across different LLM models and that the smart preview function intelligently truncates content at logical breakpoints.

## Test Coverage
- **countTokens function**: Tests token counting for various text inputs, different models, edge cases, and fallback behavior
- **getSmartPreview function**: Tests intelligent text truncation logic including handling of empty lines, maxLines limits, and edge cases

## Testing Approach
The tests use Jest with a straightforward unit testing approach, organizing tests into two main describe blocks for each utility function. Tests cover both happy paths and edge cases, including empty inputs, very long text, special characters, and boundary conditions. No mocking is required as the functions are pure utilities.

## Dependencies
- **Internal**: `./prompt` (the implementation file being tested)
- **External**: 
  - `js-tiktoken` (type imports for TiktokenModel)
  - Jest (testing framework)

## Key Test Scenarios
- Token counting with empty strings, simple text, special characters, and emojis
- Model-specific token counting (gpt-4, gpt-3.5-turbo)
- Fallback behavior for invalid models (uses length/4 estimate)
- Smart preview truncation at empty lines within bounds
- Handling of consecutive empty lines and exact boundary cases
- Content truncation with appropriate ellipsis messages

## Usage Examples
```typescript
// Example of testing token counting
const tokenCount = countTokens('Hello, world!', 'gpt-4');

// Example of testing smart preview
const preview = getSmartPreview(longText, { minLines: 5, maxLines: 10 });
```

## See Also
- `./prompt.ts` - Implementation file containing the utilities being tested
- Related prompt generation utilities in the genai-lite library

### templateEngine.ts
## Overview
This module provides a sophisticated micro-templating engine that supports variable substitution and conditional rendering. Originally migrated from the Athanor project, it enables dynamic prompt generation with support for ternary conditionals, multi-line strings in backticks, and intelligent newline handling. The engine is particularly useful for creating complex prompts that adapt based on runtime conditions.

## Key Components
- **renderTemplate(template, variables)**: Main function that processes template strings by substituting variables and evaluating conditional expressions
- **processExpression(expression, variables, leadingNewline, trailingNewline)**: Internal function that handles the actual variable substitution and conditional logic
- **Custom parser**: Implements a depth-aware parser that correctly handles nested `{{}}` patterns within backtick strings

## Architecture & Design
The module uses a custom parsing approach rather than simple regex to handle the complexity of nested template expressions. Key design features:
- **Depth-aware parsing**: Tracks brace depth to correctly match opening and closing `{{}}` pairs
- **Backtick awareness**: Special handling for backtick-delimited strings to allow nested templates
- **Intelligent newline handling**: Removes trailing newlines when substitution results in empty content
- **Recursive processing**: Supports nested variable substitutions within conditional branches

## Supported Syntax
- **Simple substitution**: `{{ variableName }}`
- **Ternary conditionals**: `{{ condition ? `true result` : `false result` }}`
- **Optional false branch**: `{{ condition ? `true result` : `` }}`
- **Nested variables**: `{{ showName ? `Hello, {{name}}!` : `Guest` }}`
- **Multi-line strings**: Backticks preserve newlines and formatting
- **Escaped backticks**: Use `\`` within backtick strings

## Dependencies
- **Internal**: None
- **External**: None (pure JavaScript implementation)

## Integration Points
This template engine is designed for:
- Dynamic prompt generation based on runtime conditions
- Configuration-driven content rendering
- Conditional inclusion of prompt sections
- Any scenario requiring lightweight templating without external dependencies

## Usage Examples
```typescript
import { renderTemplate } from 'genai-lite/utils';

// Simple variable substitution
const greeting = renderTemplate('Hello, {{ name }}!', { name: 'World' });
// Result: "Hello, World!"

// Conditional rendering
const prompt = renderTemplate(
  'Task: {{ task }}\n{{ hasContext ? `Context: {{context}}` : `` }}',
  { task: 'Analyze code', hasContext: true, context: 'TypeScript file' }
);
// Result: "Task: Analyze code\nContext: TypeScript file"

// Complex nested template
const template = `
Project: {{ projectName }}
{{ hasFiles ? `## Files
{{ fileList }}` : `No files selected` }}
`;
const result = renderTemplate(template, {
  projectName: 'MyApp',
  hasFiles: true,
  fileList: '- src/index.ts\n- src/utils.ts'
});
```

## See Also
- `./templateEngine.test.ts` - Comprehensive test suite
- Original implementation in Athanor's promptTemplates.ts

### templateEngine.test.ts
## Overview
This comprehensive test suite validates all aspects of the template engine's functionality, including variable substitution, conditional logic, nested templates, and edge cases. The tests ensure backward compatibility with quote-based syntax while validating the advanced backtick-based features and intelligent newline handling.

## Test Coverage
- **Variable substitution**: Simple replacements, undefined variables, special handling for task_context
- **Conditional logic**: Ternary expressions, optional false branches, nested conditionals
- **Backtick strings**: Multi-line support, escaped backticks, nested variables
- **Newline handling**: Intelligent trimming for empty results, preservation for non-empty results
- **Edge cases**: Empty templates, no placeholders, whitespace handling
- **Backward compatibility**: Quote-based ternary syntax (single and double quotes)

## Testing Approach
The tests use Jest with a comprehensive set of scenarios covering both common use cases and edge conditions. Each test is focused on a specific aspect of the template engine's behavior, making it easy to identify and fix issues. The test suite serves as both validation and documentation of the expected behavior.

## Key Test Scenarios
- Basic variable substitution with various data types
- Ternary conditionals with both branches
- Ternary conditionals with only true branch (empty false)
- Nested variable substitution within conditional branches
- Complex multi-level templates with multiple conditionals
- Special newline handling that removes empty lines
- Backward compatibility with older quote-based syntax

## Dependencies
- **Internal**: `./templateEngine` (implementation being tested)
- **External**: Jest (testing framework)

## See Also
- `./templateEngine.ts` - Implementation file
- Integration tests in applications using the template engine

## Architecture
The utils directory follows a modular design pattern:
1. **Index Module**: Provides a clean public API through barrel exports
2. **Prompt Module**: Contains token counting and preview generation with performance optimizations
3. **Template Engine Module**: Implements sophisticated template rendering with conditional logic
4. **Test Coverage**: Comprehensive tests ensuring reliability of all utility functions

Key architectural decisions:
- **Caching Strategy**: Tokenizer instances are cached to avoid expensive re-initialization
- **Graceful Degradation**: Token counting falls back to character estimation if tiktoken fails
- **Smart Truncation**: Preview generation looks for natural content boundaries rather than arbitrary cuts
- **Custom Parser**: Template engine uses depth-aware parsing to handle nested template expressions
- **Zero Dependencies**: Template engine has no external dependencies, ensuring lightweight integration

## Internal Dependencies
- The utils directory is self-contained with no internal dependencies on other genai-lite modules
- This design ensures utilities can be used throughout the library without circular dependencies

## External Dependencies
- `js-tiktoken` - Used for accurate token counting compatible with OpenAI's models
- Jest - Testing framework for the test suite

## Integration Points
The utils module serves as a foundational layer that can be used by:
- **LLM Service**: For token counting before API requests
- **Client Applications**: For displaying content previews and rendering dynamic prompts
- **Cost Estimation**: For calculating API usage costs based on tokens
- **Rate Limiting**: For tracking token usage against limits
- **Prompt Generation**: For creating dynamic, conditional prompts based on runtime data
- **Configuration Systems**: For template-based configuration rendering

## Usage Examples
```typescript
// In an LLM service preparing a request
import { countTokens } from 'genai-lite/utils';

const messageTokens = messages.reduce((total, msg) => 
  total + countTokens(msg.content, modelId), 0
);

if (messageTokens > modelConfig.maxContextTokens) {
  throw new Error('Context length exceeded');
}

// In a UI component showing file preview
import { getSmartPreview } from 'genai-lite/utils';

const FilePreview = ({ content }) => {
  const preview = getSmartPreview(content, {
    minLines: 20,
    maxLines: 50
  });
  return <pre>{preview}</pre>;
};

// Dynamic prompt generation
import { renderTemplate } from 'genai-lite/utils';

const promptTemplate = `
Analyze the following {{ language }} code:
{{ hasContext ? `Context: {{context}}\n` : `` }}
\`\`\`{{ language }}
{{ code }}
\`\`\`
{{ hasInstructions ? `Special instructions: {{instructions}}` : `Please provide a comprehensive analysis.` }}
`;

const prompt = renderTemplate(promptTemplate, {
  language: 'typescript',
  hasContext: true,
  context: 'React component for user authentication',
  code: fileContent,
  hasInstructions: false
});
```

## See Also
- **Parent Directory**: src/ - Main source directory
- **Related Directories**:
  - src/llm/ - May use token counting for request validation
  - src/index.ts - Exports these utilities as part of public API
- **Key Consumers**: Any module needing token counting or content preview functionality