# Directory: src/prompting/

## Overview
The prompting directory provides a comprehensive suite of utilities for advanced prompt engineering in LLM applications. It represents a significant refactoring from the original utils directory, with a clearer separation of concerns and more descriptive naming. The module is organized around the prompt engineering lifecycle: template rendering, content preparation, message building, and response parsing.

## Key Components

### index.ts
## Overview
This file serves as the central export point for all prompting utilities in the genai-lite library. It provides a clean, organized API surface by re-exporting functions from the four main modules: template rendering, content preparation, message building, and response parsing.

## Key Components
- **Template Rendering**: 
  - `renderTemplate` from `./template` - Dynamic text generation with variables and conditionals
- **Content Preparation**:
  - `countTokens` from `./content` - Token counting for cost estimation
  - `getSmartPreview` from `./content` - Intelligent content truncation
  - `extractRandomVariables` from `./content` - Few-shot example extraction
- **Message Building**:
  - `buildMessagesFromTemplate` from `./builder` - Convert templates to LLM messages
- **Response Parsing**:
  - `parseStructuredContent` from `./parser` - Extract structured data from responses

## Architecture & Design
The file follows a barrel export pattern, organizing exports by their functional area. This structure makes it clear which utility serves which purpose in the prompt engineering workflow.

## See Also
- Individual module files for implementation details
- Main `src/index.ts` for how these utilities are exposed in the library's public API

### template.ts
## Overview
This module provides the core template rendering engine, migrated from the original templateEngine.ts. It implements a sophisticated micro-templating system that supports variable substitution and conditional rendering, making it the foundation for dynamic prompt generation.

## Key Components
- **renderTemplate(template, variables)**: Main function processing templates with variable substitution and conditionals
- **processExpression**: Internal function handling variable substitution and ternary logic
- **Custom Parser**: Depth-aware parser for nested template expressions

## Architecture & Design
The module uses a custom parsing approach to handle complex nested templates:
- **Depth Tracking**: Monitors brace depth for correct `{{}}` matching
- **Backtick Support**: Special handling for multi-line strings
- **Intelligent Newlines**: Removes empty lines when substitution results are empty
- **Recursive Processing**: Supports nested variables in conditional branches

## Supported Syntax
- Simple substitution: `{{ variableName }}`
- Conditionals: `{{ condition ? `true` : `false` }}`
- Optional false: `{{ condition ? `true` : `` }}`
- Nested variables: `{{ show ? `Hello, {{name}}!` : `Guest` }}`

## Dependencies
- **Internal**: None
- **External**: None (pure TypeScript)

## Usage Examples
```typescript
import { renderTemplate } from 'genai-lite/prompting';

const prompt = renderTemplate(
  'Analyze {{ language }} code{{ hasContext ? `: {{context}}` : `` }}',
  { language: 'TypeScript', hasContext: true, context: 'React hooks' }
);
```

### content.ts
## Overview
This module consolidates content preparation utilities from the original prompt.ts and parts of promptBuilder.ts. It provides essential functions for preparing raw text content before it's assembled into prompts, including token counting, smart previews, and random example extraction.

## Key Components
- **countTokens(text, model)**: Counts tokens using model-specific tokenizers
- **getSmartPreview(content, config)**: Creates intelligent content previews
- **extractRandomVariables(content, options)**: Extracts and shuffles examples for few-shot learning
- **tokenizerCache**: Map-based cache for tokenizer instances

## Architecture & Design
The module implements several optimization strategies:
- **Tokenizer Caching**: Reuses tokenizer instances for performance
- **Graceful Fallback**: Falls back to character estimation if tokenization fails
- **Natural Boundaries**: Preview function seeks empty lines for clean truncation
- **Fisher-Yates Shuffle**: Implements proper randomization for examples

## Dependencies
- **Internal**: None
- **External**: `js-tiktoken` for accurate token counting

## Integration Points
Used throughout the library for:
- API request preparation and validation
- Content display in UIs
- Few-shot prompt construction
- Token-based cost estimation

### builder.ts
## Overview
This module focuses on building structured LLM messages from templates. It represents a refinement of the original promptBuilder.ts, with the key function renamed from `parseMessagesFromTemplate` to `buildMessagesFromTemplate` to better reflect its purpose.

## Key Components
- **buildMessagesFromTemplate(template, variables)**: Converts templates with role tags to LLM messages
- **extractTextAndClean**: Internal helper for XML-style tag extraction

## Architecture & Design
The module provides a clean abstraction for conversation construction:
- **Role Tag Support**: Handles SYSTEM, USER, and ASSISTANT tags
- **Order Preservation**: Maintains proper message sequencing
- **Variable Integration**: Works seamlessly with the template engine
- **Type Safety**: Returns properly typed LLMMessage arrays

## Supported Features
- Multiple USER/ASSISTANT turns
- Variable substitution within role tags
- Graceful handling of missing/empty tags
- Integration with template conditionals

## Dependencies
- **Internal**: 
  - `./template` for variable rendering
  - `../llm/types` for LLMMessage types
- **External**: None

## Usage Examples
```typescript
import { buildMessagesFromTemplate } from 'genai-lite/prompting';

const messages = buildMessagesFromTemplate(`
<SYSTEM>You are a {{role}} assistant.</SYSTEM>
<USER>Help me with {{task}}</USER>
`, { role: 'coding', task: 'debugging' });
```

### parser.ts
## Overview
This module provides utilities for parsing structured content from LLM responses. It was extracted from the original promptBuilder.ts to create a clear separation between prompt building and response parsing.

## Key Components
- **parseStructuredContent(content, tags)**: Extracts content from XML-style tags

## Architecture & Design
The parser is designed for flexibility and robustness:
- **Tag Order Awareness**: Processes tags in specified order
- **Flexible Matching**: Handles both closed and unclosed tags
- **Graceful Degradation**: Returns empty strings for missing tags
- **Simple API**: Single function with clear inputs/outputs

## Use Cases
- Extracting structured reasoning from LLM responses
- Parsing multi-part answers (thinking, code, explanation)
- Handling streaming responses with incomplete tags
- Building robust LLM output pipelines

## Dependencies
- **Internal**: None
- **External**: None

## Usage Examples
```typescript
import { parseStructuredContent } from 'genai-lite/prompting';

const response = `
<ANALYSIS>The code has a memory leak</ANALYSIS>
<SOLUTION>Use proper cleanup in useEffect</SOLUTION>
`;

const parsed = parseStructuredContent(response, ['ANALYSIS', 'SOLUTION']);
// parsed.ANALYSIS = "The code has a memory leak"
// parsed.SOLUTION = "Use proper cleanup in useEffect"
```

## Architecture
The prompting directory follows a clear architectural pattern aligned with the prompt engineering workflow:

1. **Template Layer** (`template.ts`): Provides the foundational rendering engine
2. **Content Layer** (`content.ts`): Prepares raw content for use in prompts
3. **Builder Layer** (`builder.ts`): Assembles structured messages for LLMs
4. **Parser Layer** (`parser.ts`): Extracts structured data from responses

This layered approach provides:
- **Clear Separation**: Each module has a distinct responsibility
- **Workflow Alignment**: Structure mirrors the prompt engineering process
- **Reusability**: Each layer can be used independently
- **Maintainability**: Changes are localized to specific concerns

## Migration from utils/
The refactoring from `src/utils/` to `src/prompting/` includes:
- **Renamed Directory**: From generic "utils" to specific "prompting"
- **Split Files**: `promptBuilder.ts` split into `builder.ts` and `parser.ts`
- **Renamed Function**: `parseMessagesFromTemplate` â†’ `buildMessagesFromTemplate`
- **Reorganized Exports**: Clear categorization in index.ts

## Dependencies
- **Internal**: Only the builder module depends on LLM types
- **External**: Only js-tiktoken for token counting

## Integration Points
The prompting module serves as a foundational layer for:
- **LLM Service**: Message preparation and response parsing
- **Client Applications**: Dynamic prompt generation
- **Cost Management**: Token counting and estimation
- **Content Display**: Smart previews and truncation
- **Few-shot Learning**: Example extraction and randomization

## Testing
Each module has comprehensive test coverage:
- **template.test.ts**: 20+ tests covering all template features
- **content.test.ts**: Tests for token counting, previews, and random extraction
- **builder.test.ts**: Message building and role tag handling
- **parser.test.ts**: Structured content extraction scenarios

## Usage Examples
```typescript
import { 
  renderTemplate,
  countTokens,
  buildMessagesFromTemplate,
  parseStructuredContent 
} from 'genai-lite/prompting';

// Complete prompt engineering workflow
const template = `
<SYSTEM>You are a code review expert.</SYSTEM>
<USER>Review this {{language}} code:
\`\`\`{{language}}
{{code}}
\`\`\`
</USER>
`;

// 1. Prepare content
const codeTokens = countTokens(code, 'gpt-4');
if (codeTokens > 1000) {
  code = getSmartPreview(code, { minLines: 50, maxLines: 100 });
}

// 2. Build messages
const messages = buildMessagesFromTemplate(template, {
  language: 'TypeScript',
  code: code
});

// 3. Send to LLM and parse response
const llmResponse = await llm.sendMessage(messages);
const parsed = parseStructuredContent(llmResponse, [
  'ISSUES', 
  'SUGGESTIONS', 
  'SECURITY_CONCERNS'
]);
```

## See Also
- **Parent Directory**: src/ - Main source directory
- **Related Modules**:
  - src/llm/ - Uses these utilities for message handling
  - src/index.ts - Exports these utilities in public API
- **Migration Notes**: Applications using old paths need updates